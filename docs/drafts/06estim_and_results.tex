\section{Estimation and Results} \label{sec:estim_res}
We implement the partially linear model as presented in Section X.X to estimate the effect of receiving a tax rebate of $R_{it}$ on change of consumption $\Delta C_{it}$
\begin{align}
    \Delta C_{it+1}&=\theta(X_{it})R_{it+1}+g(X_{it}, W_{it})+\epsilon_{it} \label{eq:plm_C1}\\
    R_{it}&=h(X_{it}, W_{it})+u_{it} \label{eq:plm_C2}
\end{align}
Which variables are included as confounders $X_{it}$ and $W_{it}$ and which make up $X_{it}$ depends on our specification and is named in the section discussing the respective results. In each specification we include monthly dummies to account for seasonality. They also capture any unobserved effects that might appear when households learn about the rebate, i.e. in line with Parker et al./Misra and Surico our estimation uncovers the effect of actually receiving the rebate. \\ 
In total, we estimate four different specifications for each outcome. By specification we refer to which variables we include as confounders $X$ and $W$ whereas we additionally distinct between the estimator used for the second stage. Thus, we estimate each outcome-specification pair twice: once using the linear and once using the causal forest (cf) second stage. Since our estimation procedure predicts MPCs and we retrieve standard errors, we can run hypothesis tests on whether the estimated response to the tax rebate is statistically significant for each household. 

\subsection{Identifying the Income Shock} \label{subsec:identification}
Since we use the same data and event to estimate the MPC our identification is based on the approach by Parker et al. (2013). The main factor is the design of the stimulus rollout, which we can exploit to identify the income shock. The tax stimulus was paid out to households over several weeks as administrative and technological restrictions made it impossible to pay out all rebates at once. Instead the date of rebate receipt depended on the last two digits of tax filers' social security number. Therefore, we observe rebate receipts at different points in time, which allows us to use all other households that received their rebate in a different quarter as the control group. \\
% \textbf{the following is probably to harsh self-criticism and too much into econometric stuff; on the other hand the definition of the control group is quite crude}
% This definition of the control group is obviously problematic. Question: deal with this here or have a paragraph in the end that deals with shortcomings of the identification section? No matter where, it should go something like this: 
% This definition of a control group is potentially problematic as it also includes households that already received their rebate in a prior period. This might bias our results if there are long term effects of receiving the rebate that spill into the next period. Also, it leaves the consumption change from t-1 to t in the control group biased in case households receiving the rebate in t-1  actually respond positively to the rebate. Then the change in the control group is likely to be negative as in the next period households resume their smoother consumption pattern and therefore show a negative consumption change although this is due to the control group. This biases the effect of receiving the rebate upwards as even when reactions are small the divergence is larger than the reaction itself (thisreads shaky and I am not sure whether I should include such harsh criticism of my own work here).
% However, Parker et al. (2013) (or was it MS?) include a one period lag of rebate in their analysis and find no significant role of it in determining consumption change. 
% \\
In the following, we will slightly depart from Parker et al.'s identification strategy given their findings as well as our inclusion of more control variables. They argue that using the actual amount of tax rebate received can lead to an omitted variable bias. This concern arises because of how households' stimulus payments are determined. First, they depend on the number of children as each dependent child adds 300 USD to the stimulus amount. Second, the stimulus excluding the child bonuses equals the household's net income tax liability (NTL; in the following also referred to as the net tax liability) as long as it is within the exogenously defined boundaries we discussed in Section 3.1. Parker et al. now argue that the NTL might also drive changes in consumption, rendering the treatment endogenous. Their solution is to instrument the amount received with a dummy variable that only signals whether the stimulus was received or not in the given quarter. While their results and the authors themselves suggest that this is not much of a concern, we decisively disagree with their identification approach. With respect to the first concern, the number of children is reported in the CEX and is easily controlled for as it is collected in each interview conducted. The role of the NTL is more complicated. Parker et al. do not control for any variable related to households income or salary, These variables are without a doubt directly connected to our treatment because the NTL is determined by income. Exlcuding these variables leads to an omitted variable biases that leads to inconsistent estimates. However, other than through the channel of income, we deem it highly unlikely that the net tax liability itself is driving changes in consumption. It might be possible that in other years the NTL plays a role for households income as it can be perceived as an anticipated income - or liquidity - shock (\footnote{Households usually should know that they will have to pay this/receive this because of past experience and because the NTL is also depending on how much income tax was already paid during the previous year.}) However, in 2008 the NTL affected households via their tax rebate, i.e. it does not affect the consumption change through other channels than what is captured by the tax rebate. Therefore, we argue in favor of using the actual rebate amount since it has two advantages: for one, we have an additional source of variation and second it allows us to estimate the continuous treatment effect and interpret it as the actual MPC in dollar amount. \\
However, one drawback of the already mentioned lack of detailed documentation of household characteristics in the CEX is the fact that once we include financial variables - most importantly liquidity and salary - our sample size shrinks because they are not consistently documented for each interviewed households. Although the DML framework achieves fast convergence rates even in cases in which the first stage predictions do not converge as rapidly, we have to keep this drawback in mind. However, contrary to Misra and Surico, we actually recover the conditional distribution of the MPC - obviously under the assumption that we control for any relevant confounders **(NOT A SENTENCE YET AND THINK ABOUT THIS IN MORE DETAIL)** - ****and contrary to Parker et al. we do not have to rely on defining our own cutoffs to detect heterogeneities. 

\subsection{Main Results}
We analyse our results in several steps and we begin by looking at the empirical distribution of the estimated MPCs. Figure X.X shows the distribution of MPCs for the four expenditure categories Parker et al. look at: Food (FD), Strictly Non-Durables (SND) as defined by Lusardi (1996), Non-Durables (ND) and Total (TOT) expenditure. These categories are increasing in their level of aggregation, e.g. SND includes expenditures on food. A detailed list of all sub-components of each of these categories is listed in Appendix X.X. Here we only want to point out that the difference between SND and ND consumption categories are so-called 'semi-durables',such as health expenditures, which are not included in the SND category. \\
A single plot of the empirical distribution in Figure X.X is retrieved as follows. We slice the range between the minimum and maximum of the point estimates into 20 equidistant bins and calculate the share of estimated MPCs that fall into each bin. The x-axis signals the borders of the different bins and the y-axis shows the respective frequency. The blue bar signals what the total frequency of this bin is. To illustrate how many of these estimates are actually rejecting the null of a zero MPC, we calculate the share of point estimates that reject the null at the 10\% level within each bin. This is depicted by the read overlay over the frequency bars. I.e. a completely red bar implies that all observations within this bin are statistically significant whereas a bar that is only red up to half of its height signals that only half of the point estimates within this bar are statistically significant. The vertical dashed line marks the average CATE - the average treatment effect across all households - as a benchmark. The plot description notes whether this ATE is significant or not. \\ 
First, we have a look at global trends across all specifications and expenditure categories before we start taking a closer look at each category and estimation procedure. \\
Across all specifications, outcomes and estimators we find a strong pattern of heterogeneity. This underlines the importance of accounting for heterogenous responses to income shocks. The heterogeneity is in part similar to what Kaplan and Violante's theoretical model suggests and what Misra and Surico find as well. Namely, there is a large part of households that have a zero or almost zero response but a certain share of households react significantly. However, contrary to Misra and Surico, this share of households is substantially smaller in our analysis, especially once we control for liquidity. Table X.X depicts the shares of significant MPCs we estimate for each specification and model when we look at changes in non-durable consumption. Most importantly though, we find that the ATE is always very close to zero but the individual point estimates show a completely different pattern. We see that the ATE falls into bins that have the (almost) highest frequency - which makes sense by construction - but across all estimations the respective bin never contains more than 15\% of all point estimates. This highlights the weak representativeness of the ATE and its inability to reliably assess the success of programs such as the 2008 tax stimulus. \\
Also we see that introducing more controls to our estimation reduces the spread of the point estimates no matter at which outcome and estimator we look at. The change is the most pronounced once we add liquid assets, income and salary as confounders to the estimation. \\
Curiously at first, the responses we find for total expenditures are unreasonably large for a bulk of individuals. This is probably due to the underlying composition of the total expenditure variable and our estimation approach. It is quite likely that some outliers within a specific spending category part of TOT are driving the learning behavior of our estimators. This is underlined by the fact the the causal forest estimator finds way larger responses than the linear based estimator because nonparametric machine learning estimators are often performing weakly when they encounter unusual combinations of confounders and outcomes. (check how much is spent on cars etc in test sample). Also, it is important to note that in both estimators the spread of the CATE is drastically reduced once we control for liquidity, salary and income - variables we expect to be closely related to the MPC. Turning to the significance of the response, we see that adding more controls also reduces the amount of significant MPCs found; suggesting that prior specifications pick up signals of the confounding factors not included and interpret them as signals of the rebate. Concluding, it seems that our estimation procedure is quite sensitive to extreme outliers in the underlying consumption categories as for total expenditure we find extreme responses as laid out above. This notion becomes more clearly when we turn to the non-durable and strictly non-durable goods. Excluding large durable categories such as *new vehicles* immediately reduces our estimated MPCs and their spread. Moreover, looking at the ND category we see that in specification 3, which includes liquidity, the linear model fails to reject the null for all households. Interestingly though, the causal forest model still finds a small fraction of large significant MPCs. This difference suggests that there are non-linearities in the dependence of the MPC on the variables such as liquidity - and potentially with respect to their interactions - that are ignored by the linear model but detected by the causal forest. Accounting for these non-linearities reduces the noise in the point estimates and reveals significant MPCs where the linear analysis fails to pick up any significant MPCs. Comparing this to the Strictly Non-Durable category there is little difference in the distribution and significance of the recovered MPCs. 