\section{Methodology} \label{sec:methodology}
To estimate the causal effect of tax rebate receipt on changes in consumption, we use the Double Machine Learning (DML) framework developed by \cite{DML2017}. This new kind of estimation approach allows to efficiently estimate semi- or non-parametric models of treatment effects. It has the major advantage that it does not restrict the effect of confounders on the outcome to a specific functional form. Instead it uses Machine Learning methods to freely estimate this relationship. Through the orthogonalization step discussed below it takes care of any confounding effects and cleanly estimates the pure effect of treatment on the outcome. Moreover, specific DML estimators enable us to estimate heterogeneity given observables without defining in which form the observable affects the treatment effect. Past contributions that were looking into heterogeneity had to rely on choosing the correct interactions with observables. On the other hand, sophisticated DML estimators can detect these interactions without knowing them beforehand. \\
Meanwhile, its implementation procedure deals with common biases arising in more naive estimation procedures that employ Machine Learning methods. This opens the door to combine powerful machine learning algorithms - proven to perform well in detecting patterns in data - with causal inference. \\
From a more theoretical perspective the DML estimator yields very efficient properties when it comes to its asymptotic behaviour. Under certain assumptions, \cite{DML2017} are able to prove root-n consistency of the estimator, a rate of convergence not achieved in other nonparametric estimators. However, we will not further elaborate on these details and refer the reader to \cite{DML2017} for a more technical discussion. Instead we focus on the general idea behind the approach and the different estimation methods we use in our analysis.

\subsection{Setup} \label{sec:dml-idea}
We start with considering a Partially Linear Model of treatment and outcome 
\begin{align}
    Y_{it}&=\theta(X_{it})D_{it}+g(X_{it}, W_{it})+\epsilon_{it} \label{eq:plm1}\\
    D_{it}&=h(X_{it}, W_{it})+u_{it}, \label{eq:plm2}
\end{align}
where $Y_{it}$ is the outcome, $D_{it}$ is the treatment and $X_{it}$ and $W_{it}$ are observable variables. We distinct between simple confounders $W_{it}$ which affect the outcome and also potentially the treatment and $X_{it}$ which additionally are considered to impact the average treatment effect of $D_{it}$ on $Y_{it}$. The choice of these variables is left to the researcher. We are interested in $\theta(X)$, the conditional average treatment effect (CATE). In Rubin's potential outcomes framework it is defined as 
\begin{align*}
    \theta(X)=E[Y_1 - Y_0 | X=x]
\end{align*}
where $Y_d$ is the outcome when treatment is $D=d$. In our setting, treatment is not binary but continuous, hence $\theta(X)$ represents the marginal CATE
\begin{align*}
    \theta(X)=E\left[\frac{\delta Y(d)}{\delta d} \bigg| X=x\right].
\end{align*}
The marginal CATE measures how much a marginal increase in the continuous treatment changes the outcome for individuals that have a set of characteristics $X=x$. The task is now to find an appropriate estimator to find $\hat{\theta}(X_{it})$.

\subsection{Regularization bias and how to get rid of it - alternative title: A quest to avoid biases}
As \cite{DML2017} point out, we could come up with some seemingly straightforward approach to estimate the PLM using machine learning methods. For example, approximating the function $g(X, W)$ with a high polynomial and using a Lasso regression for regularization or use a combination of random forests for predicting $g(X, W)$ and then an OLS regression to find $\theta(X)$. However, any machine learning based approach that follows this notion will suffer from a bias due to regularization. To avoid overfitting and the resulting large variance of the estimator, machine learning methods deliberately induce a bias into their predictions. This bias does not vanish asymptotically, leading to inconsistent results.\footnote{See Appendix X.X (or only the paper?).} However, we can deal with this regularization bias using orthogonalization. For this, we define 
\begin{align}
    E[Y_{it}|X_{it}, W_{it}] &\equiv f(X_{it}, W_{it}) \label{eq:EY_def}\\ 
    E[D_{it}|X_{it}, W_{it}] &\equiv h(X_{it}, W_{it}) \label{eq:ED_def}
\end{align}
where (\ref{eq:ED_def}) follows from (\ref{eq:plm2}). It is straightforward to estimate these conditional means using any ML method of choice. Using these and the PLM defined above, we can find 
\begin{align}
    Y_{it}-f(X_{it}, W_{it})=\theta(X_{it})(D_{it}-h(X_{it}, W_{it})) + \epsilon_{it}. \label{eq:maineq_ortho}
\end{align}
Subtracting the conditional means from $Y$ and $D$ is known as orthogonalization and removes the impact of $X$ and $W$ on them, respectively. The residuals only contain variation that does not stem from any of the confounders. In Section \ref{sec:estim_res} (\textbf{make reference to subsection in which we discuss identification}) we discuss what this means in our setting in more detail. Indeed, the estimate of $\theta(X)$ retrieved from  estimating the orthogonalized PLM in (\ref{eq:maineq_ortho}) is no longer suffering from the regularization bias. Excitingly, the authors are able to prove that even in case that the first stage estimators of $\hat{f}$ and $\hat{h}$ are converging at slower rates than $\sqrt{n}$ to the true parameter value, in the final estimator, the regularization bias clearly converges to zero and can achieve root-n consistency. \\
In practice, the first stage of the estimation process consists of choosing an appropriate Machine Learning method, predicting the conditional expectation functions $f$ and $h$ and calculating residuals 
\begin{align*} 
    \tilde{Y}_{it}&=Y_{it}-\hat{f}(X_{it}, W_{it}) \\ 
    \tilde{D}_{it}&=D_{it}-\hat{h}(X_{it}, W_{it}).
\end{align*}
A welcome property of the DML estimation is its agnostic to the first stage estimator. Thus, it allows choosing the appropriate prediction method for the given setting. 

\subsection{Cross- against Overfitting} \label{sec:cross-fitting}
While orthogonalization takes care of the regularization bias plaguing more naive ML based estimators, it impliclty induces a new bias. Machine Learning estimators are prone to overfitting models. Instead of picking up signals in features to predict the outcome, they start interpreting noise in the data. To avoid this behaviour, one can tune hyperparameters of the algorithm of choice to minimize this issue known as overfitting. Still, it is not unlikely that noise in the data is interpreted as a signal. While there is a vast literature on this issue on its own, this also leads to problems when following the procedure described so far. \\
The noise picked up in the first stage predictions stems from the error terms $\epsilon_{it}$ and $u_{it}$ in (\ref{eq:plm1}) and (\ref{eq:plm2}). Therefore, the predictions $\hat{f}$ and $\hat{g}$ are driven by these error terms. When we now calculate the respective residuals of outcome and treatment, these are by construction correlated with the error terms, which also appear in the seocnd stage estimation of \textbf{this is not 100\% true, check DML paper again}. Similarly to the regularization bias this lets the asymptotic variance of the estimator explode and prohibit any convergence. However, it is rather easy to resolve this issue using sample splitting - a procedure called "crossfitting." \\ 
Instead of using all observations to find the estimates of $f$ and $h$ and then estimate $\theta(X)$ using the whole sample, consider the case in which we split the sample into two. The first sample is used to retrieve the first stage predictions. Those are used to predict the conditional means of the second sample, which are then subsequently used for orthogonalization and the second stage estimation. Since the errors are assumed to be i.i.d., noise in one sample is not correlated with the noise in the other \textbf{don't like this sentence yet}. In case we are interested in the unconditional average treatment effect (ATE), this procedure is repeated with the role of the samples reversed and the resulting estimators are averaged. However, in the CATE case we are interested in individual-level point estimates. Therefore, while the role of both samples are switched, we do not average any results but keep the individual level estimates of all observations. The cross-fitting procedure for splitting up the sample into any K folds is described in Algorithm 1, which summarizes summarizes the whole DML framework.\footnote{Note that \cite{DML2017} argue that K=4 or K=5 performs reasonably well, even for smaller samples.} 

\subsection{Retrieving the CATE}
After retrieving the residualized outcome and treatment, the second stage estimates the conditional average treatment effect as defined in (\ref{eq:CATE}). We assume that it takes the following form
\begin{align} 
    \theta(X)=\phi(X) \times \Theta, \label{eq:CATE}
\end{align} 
where $\Theta$ is the baseline treatment effect of each individual and $\phi(X)$ is a mapping of our controls $X$. The form of the latter depends on the estimator chosen for the second stage. In \cite{DML2017} estimators are proposed which have a linear second stage, either using a standard OLS estimator or Lasso to regress $\tilde{Y}_{it}$ on $\tilde{D}_{it}$. In these cases, the second stage boils down to a linear regression in which the residualized outcome is regressed on interactions $\tilde{D}_{it}$ and each element of $X_{it}$. This implies that the treatment effect we estimate is linear in the covariates $X$. It is also possible to include polynomials of or interactions between different elements of $X_{it}$. However, we choose a simple linear mapping of $X$ for our linear DML approach presented in Section \ref{sec:estim_res}. To identify nonlinearities in the CATE, we use a nonparametric approach that allows us to uncover these without defining them beforehand. Namely, we use a Generalized Random Forest estimator introduced by Athey et al. (2018). It has been developed to take advantage of the powerful random forest predictor for causal inference. Similar to DML, the GRF is an estimation framework. When using it for moment conditions such as REF TO Moment Condition it is similar/the same (?) as the Causal Forest presented in Athey and Wager (2016) and is often referred to it with the same name. The Causal Forest replaces the original objective function of the random forest algorithm (Breiman, 2001) with a moment condition containing some loss function that can be defined by the researcher. Morevoer, they develop the theory that allows retrieving standard errors of the estimated coefficients. Appendix A elaborates in more detail how the Causal Forest algorithm works and how it identifies the treatment effect. In our case the moment condition is defined as (EconML, 2020)
\begin{align*}
    E \left[Y- <\phi(X), Y> - \beta(x) \right].
\end{align*}
\textbf{This has to look better and be more 'algorithmic'.}
\begin{algorithm}
    \caption{Double Machine Learning Estimator}
    \begin{algorithmic}[1]
        \State Split up sample into K folds. 
        \State To estimate $\widehat{h}$ and $\widehat{f}$ for for the $k^{th}$ fold use observations $j \notin k$. 
        \State To get residuals for observations in $k$, calculate $\widehat{h}(X_i)$ and $\widehat{f}(X_i, W_i)$ for $i \in k$ and use to retrieve residuals.
        \State Once residuals of each fold retrieved, estimate $\theta(X_i)$.
    \end{algorithmic}
\end{algorithm}
As part of our analysis we will compare the results to check whether the relationship is indeed linear or whether we discover non-linear heterogeinities that the linear DML approach does not account for and have not been considered in literature yet. However, note that when using a nonparametric second stage the convergence rate of the estimator declines. While still achieving faster rates than most other nonparametric estimators, this implies that the Causal Forest based approach is more demanding when it comes to the number of observations. 