\newpage
\section{Methodology} \label{sec:methodology}

% \subsection{Notes on Methodology for writing}
% \begin{itemize}
%     \item see: \url{https://econml.azurewebsites.net/_autosummary/econml.dml.DML.html#econml.dml.DML}
%     \item how is the CATE achieved in second stage?
%     \begin{itemize}
%         \item second stage in Linear DML is OLS regression 
%         \item CATE is achieved through interaction of some mapping $\phi(X)$ of the confounders $X$ with the 'base' treatment effect $\Theta$.
%         \item effectively running an OLS regression with interaction terms $\tilde{D} \otimes \phi(X)$ 
%         \item hence, assume that CATE is linear in X unless using polynomial mapping $\phi(X)$ 
%         \item nonparametric DML such as Causal Forest DML circumvents this assumption and detects non-linear heterogeneity in case there is any (run this as kind of robustness check/better specification)
%     \end{itemize}
%     \item causal forests/generalized random forests: 
%     \begin{itemize}
%         \item random forests only allow for prediction, no inference possible 
%         \item Athey and Wager (2016) and Athey, Tibshirani and Wager (2019) develop causal forests/grf
%         \item these allow to estimate any desired local moment equation - e.g. those of a treatment effect analysis 
%         \item more specifically, in the DML case the moment equation estimated is 
%         \begin{align*}
%             E\big[\left(Y-E[Y|X, W] - <\theta(X), T-E[T|X, W]> - \beta(x)\right) (T; 1)|X=x\big]=0
%         \end{align*}
%         \item I should push this explanation into the Appendx though and just explain the GRF in more general terms (it detects heterogeneity that is not specified before)
%     \end{itemize}
% \end{itemize}
To estimate the causal effect of tax rebate receipt on changes in consumption, we use the Double Machine Learning (DML) framework developed by \cite{DML2017}. This new kind of estimation approach allows to efficiently estimate semi- or non-parametric models of treatment effects. It has the major advantage that it does not restrict the effect of confounders on the outcome to a specific functional form. Instead it uses Machine Learning methods to freely estimate this relationship. Through the orthogonalization step discussed below it takes care of any confounding effects and cleanly estimates the pure effect of treatment on the outcome. Moreover, specific DML estimators enable us to estimate heterogeneity given observables without defining in which form the observable affects the treatment effect. Past contributions that were looking into heterogeneity had to rely on choosing the correct interactions with observables. On the other hand, sophisticated DML estimators can detect these interactions without knowing them beforehand. \\
Meanwhile, its implementation procedure deals with common biases arising in more naive estimation procedures that employ Machine Learning methods. This opens the door to combine powerful machine learning algorithms - proven to perform well in detecting patterns in data - with causal inference. \\
From a more theoretical perspective the DML estimator yields very efficient properties when it comes to its asymptotic behaviour. Under certain assumptions, \cite{DML2017} are able to prove root-n consistency of the estimator, a rate of convergence not achieved in other nonparametric estimators. However, we will not further elaborate on these details and refer the reader to \cite{DML2017} for a more technical discussion. Instead we focus on the general idea behind the approach and the different estimation methods we use in our analysis.

\subsection{Setup} \label{sec:dml-idea}
We start with considering a Partially Linear Model of treatment and outcome 
\begin{align}
    Y_{it}&=\theta(X_{it})D_{it}+g(X_{it}, W_{it})+\epsilon_{it} \label{eq:plm1}\\
    D_{it}&=h(X_{it}, W_{it})+u_{it}, \label{eq:plm2}
\end{align}
where $Y_{it}$ is the outcome, $D_{it}$ is the treatment and $X_{it}$ and $W_{it}$ are observable variables. We distinct between simple confounders $W_{it}$ which affect the outcome and also potentially the treatment and $X_{it}$ which additionally are considered to impact the average treatment effect of $D_{it}$ on $Y_{it}$. The choice of these variables is left to the researcher. We are interested in $\theta(X)$, the conditional average treatment effect (CATE). In Rubin's potential outcomes framework it is defined as 
\begin{align*}
    \theta(X)=E[Y_1 - Y_0 | X=x]
\end{align*}
where $Y_d$ is the outcome when treatment is $D=d$. In our setting, treatment is not binary but continuous, hence $\theta(X)$ represents the marginal CATE
\begin{align*}
    \theta(X)=E\left[\frac{\delta Y(d)}{\delta d} \bigg| X=x\right].
\end{align*}
The marginal CATE measures how much a marginal increase in the continuous treatment changes the outcome for individuals that have a set of characteristics $X=x$. The task is now to find an appropriate estimator to find $\hat{\theta}(X_{it})$.

\subsection{Regularization bias and how to get rid of it - alternative title: A quest to avoid biases}
As \cite{DML2017} point out, we could come up with some seemingly straightforward approach to estimate the PLM using machine learning methods. For example, approximating the function $g(X, W)$ with a high polynomial and using a Lasso regression for regularization or use a combination of random forests for predicting $g(X, W)$ and then an OLS regression to find $\theta(X)$. However, any machine learning based approach that follows this notion will suffer from a bias due to regularization. To avoid overfitting and the resulting large variance of the estimator, machine learning methods deliberately induce a bias into their predictions. This bias does not vanish asymptotically, leading to inconsistent results.\footnote{See Appendix X.X (or only the paper?).} However, we can deal with this regularization bias using orthogonalization. For this, we define 
\begin{align}
    E[Y_{it}|X_{it}, W_{it}] &\equiv f(X_{it}, W_{it}) \label{eq:EY_def}\\Â 
    E[D_{it}|X_{it}, W_{it}] &\equiv h(X_{it}, W_{it}) \label{eq:ED_def}
\end{align}
where (\ref{eq:ED_def}) follows from (\ref{eq:plm2}). It is straightforward to estimate these conditional means using any ML method of choice. Using these and the PLM defined above, we can find 
\begin{align}
    Y_{it}-f(X_{it}, W_{it})=\theta(X_{it})(D_{it}-h(X_{it}, W_{it})) + \epsilon_{it}. \label{eq:maineq_ortho}
\end{align}
Subtracting the conditional means from $Y$ and $D$ is known as orthogonalization and removes the impact of $X$ and $W$ on them, respectively. The residuals only contain variation that does not stem from any of the confounders. In Section \ref{sec:estim_res} (\textbf{make reference to subsection in which we discuss identification}) we discuss what this means in our setting in more detail. Indeed, the estimate of $\theta(X)$ retrieved from  estimating the orthogonalized PLM in (\ref{eq:maineq_ortho}) is no longer suffering from the regularization bias. Excitingly, the authors are able to prove that even in case that the first stage estimators of $\hat{f}$ and $\hat{h}$ are converging at slower rates than $\sqrt{n}$ to the true parameter value, in the final estimator, the regularization bias clearly converges to zero and can achieve root-n consistency. \\
In practice, the first stage of the estimation process consists of choosing an appropriate Machine Learning method, predicting the conditional expectation functions $f$ and $h$ and calculating residuals 
\begin{align*} 
    \tilde{Y}_{it}&=Y_{it}-\hat{f}(X_{it}, W_{it}) \\ 
    \tilde{D}_{it}&=D_{it}-\hat{h}(X_{it}, W_{it}).
\end{align*}
A welcome property of the DML estimation is its agnostic to the first stage estimator. Thus, it allows choosing the appropriate prediction method for the given setting. 

\subsection{Cross- against Overfitting} \label{sec:cross-fitting}
\textbf{this needs more detail and rephrasing}
While orthogonalization takes care of the regularization bias plaguing more naive ML based estimators, it impliclty induces a new bias. Machine Learning estimators are prone to overfitting models. Instead of picking up signals in features to predict the outcome, they start interpreting noise in the data. To avoid this behaviour, one can tune hyperparameters of the algorithm of choice to minimize this issue known as overfitting. Still, it is not unlikely that noise in the data is interpreted as a signal. While there is a vast literature on this issue on its own, this also leads to problems when following the procedure described so far. \\
The noise picked up in the first stage predictions stems from the error terms $\epsilon_{it}$ and $u_{it}$ in (\ref{eq:plm1}) and (\ref{eq:plm2}). Therefore, the predictions $\hat{f}$ and $\hat{g}$ are driven by these error terms. When we know calculate the respective residuals of outcome and treatment, these are by construction correlated with the error terms, which also appear in the seocnd stage estimation of \textbf{here reference of equation of estimation of second stage - right now this is nowhere but I have to show it}. Similarly to the regularization bias this lets the asymptotic variance of the estimator explode and prohibit any convergence. However, it is rather easy to resolve this issue using sample splitting - a procedure called "crossfitting." \\ 
Instead of using all observations to find the estimates of $f$ and $h$ and then estimate $\theta(X)$ using the whole sample, consider the case in which we split the sample into two. The first sample is used to retrieve the first stage predictions. Those are used to predict the conditional means of the second sample, which are then subsequently used for orthogonalization and the second stage estimation. Since the errors are assumed to be i.i.d., noise in one sample is not correlated with the noise in the other \textbf{don't like this sentence yet}. In case we are interested in the unconditional average treatment effect (ATE), this procedure is repeated with the role of the samples reversed and the resulting estimators are averaged. However, in the CATE case we are interested in individual-level point estimates. Therefore, while the role of both samples are switched, we do not average any results but keep the individual level estimates of all observations. The cross-fitting procedure for splitting up the sample into any K folds is described in Algorithm 1, which summarizes summarizes the whole DML framework.\footnote{Note that \cite{DML2017} argue that K=4 or K=5 performs reasonably well, even for smaller samples.} 

\subsection{Retrieving the CATE}
The second stage then only consists of a linear regression of $\tilde{Y}_{it}$ on $\tilde{D}_{it}$ that yields $\hat{\theta}(X)$. More precisely, the partially linear model we consider here implicitly assumes a parametric form of the CATE 
\begin{align*} 
    \theta(X)=\phi(X) \times \Theta,
\end{align*}Â 
where $\Theta$ is the base treatment effect and $\phi(X)$ is a mapping of confounders $X$. In practice, the estimator boils down to a linear regression which includes interaction terms $\tilde{D} \otimes \phi(X)$. The mapping $\phi(X)$ can take any parametric form we might think of. In Section \ref{sec:NP-DML} we discuss how this assumption can be avoided, allowing to detect any heterogeneity without pre-defining its functional form. 

\textbf{This has to look better and be more 'algorithmic'.}
\begin{algorithm}
    \caption{Double Machine Learning Estimator}
    \begin{algorithmic}[1]
        \State Split up sample into K folds. 
        \State To estimate $\widehat{h}$ and $\widehat{f}$ for for the $k^{th}$ fold use observations $j \notin k$. 
        \State To get residuals for observations in $k$, calculate $\widehat{h}(X_i)$ and $\widehat{f}(X_i, W_i)$ for $i \in k$ and use to retrieve residuals.
        \State Once residuals of each fold retrieved, estimate $\theta(X_i)$.
    \end{algorithmic}
\end{algorithm}

\subsection{Nonparametric DML} \label{sec:NP-DML}
In the PLM setting, the functional relationship how the CATE is influenced by confounders $X$ via the mapping $\phi(X)$. However, the DML estimator also enables us to use a nonparametric approach that can detect any interaction between treatment and confounders to uncover heteroegeneity. It has the same first stage, but estimates the second stage using the Causal Forest estimator proposed by Athey, Tibshirani and Wager (????) \textbf{citation missing}. The Causal Forest is a generalization of the Random Forest prediction method developed by Breimann (2001) \textbf{citation missing}, which has found application in a wide array of predictive tasks. However, the original algorithm - as most Machine Learning methods focusing on prediction - does not allow for any causal inference. The Causal Forest solves this problem by generalizing the objective function of the random forest algorithm to fit the potential outcomes framework. Morevoer, they develop the theory that allows retrieving standard errors of the estimated coefficients. Appendix A elaborates in more detail how the Causal Forest algorithm works and how it identifies the treatment effect. Using the CF as a second stage enables us to estimate the model 
\textbf{THIS IS NOT TRUE!!!!}
Instead it still assumes that the effect is linear in treatment but no loinger linear in X ! -> we cannot say anything about what effect size of treatment has on MPC but we can identify any non-linear patterns without relying on specifying the correct polynomial and set of interactions.
\begin{align*}
    Y_{it}&=g(D_{it}, X_{it}, W_{it})+\epsilon_{it} \\ 
    D_{it}&=m(D_{it}, X_{it}, W_{it})+u_{it}.
\end{align*}
As part of our analysis we will compare the results to check whether the relationship is indeed linear or whether we discover non-linear heterogeinities that the linear DML approach does not account for and have not been considered in literature yet. However, note that when using a nonparametric second stage the convergence rate of the estimator declines. While still achieving faster rates than most other nonparametric estimators, this implies that the Causal Forest based approach is more demanding when it comes to the number of observations. 