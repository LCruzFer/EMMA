\section*{Methodology}
\textbf{rewrite this intro and specify that this is a two-stage approach}

To identify the causal effect of receiving the tax rebate on households' consumption changes, I use the Double Machine Learning approach (DML) developed by \cite{DML2017} and extended for Panel Data settings by \cite{PanelDML}. More precisely, this approach estimates a Partially Linear Model (PLM) of the form
\begin{align}
    Y_{it}&=\theta(X_{it})T_{it}+g(X_{it}, W_{it})+\epsilon_{it} \label{eq:plm1}\\
    T_{it}&=h(X_{it}, W_{it})+u_{it}, \label{eq:plm2}
\end{align}
where $Y_{it}$ is the outcome and the goal is to estimate the conditional treatment effect $\theta(X)$ of treatment $T_{it}$. The functions $g(X_{it}, W_{it})$ and $h(X_{it}, W_{it})$ are some non-parametric functions. Hence, the DML approach has the advantage that the effects of the confounders on treatment and outcome do not have to be formalized into a specific functional form. To remove these effects the DML estimator suggests a two-stage approach to orthogonalize treatment and outcome with respect to the confounders and uncover the causal effect of the treatment on outcome. Orthogonalization removes any variation in the two variables that is due to the confounders $(X_{it}, W_{it})$ by removing the conditional mean of the respective variable. The orthogonalized version of (\ref{eq:plm1}) is then
\begin{align}
    \Delta C_{it}-E[\Delta C_{it}|X_{it}, W_{it}]=\theta(X_{it})(R_{it}-E[R_{it}|X_{it}, W_{it}])+\epsilon_{it}
\end{align}
and I denote
\begin{align}
    E[R_{it}|X_{it}, W_{it}]&=h(X_{it}, W_{it}) \\
    E[\Delta C_{it}|X_{it}, W_{it}]&=f(X_{it}, W_{it}).
\end{align}
The advantage of the DML approach is that the two conditional means can be estimated by any machine learning method, hence guaranteeing strong flexibility of the estimation. At the same time, the DML's asymptotic properties are outperfoming other non-parametric methods in terms of the rate of consistency making it less data-hungry than standard econometric approaches. In my case, I use a random forest to predict the first stage functions $\hat{f}(X_{it}, W_{it})$ and $\hat{g}(X_{it}, W_{it})$. The random forest has proven reliable and efficient in a wide variety of prediction tasks without making any assumptions on the functional form. Hence, contrary to the existing literature, I capture any interactions and power series of the confounders that affect the treatment or outcome variable. \\ 
Once the first stage estimation 
\begin{align}
    \tilde{Y}_{it}&=Y_{it}-\hat{f}(X_{it}, W_{it})\\
    \tilde{R}_{it}&=R_{it}-\hat{h}(X_{it}, W_{it})
\end{align}

\subsection*{Panel DML Recipe}
\begin{algorithm}
    \caption{Panel DML Recipe}
    \begin{algorithmic}[1]
        \State Partition the data into K-folds based on their time index. An observation is added to partition $I_k$ if: 
                $$I_k=\left\{(i, t) : \floor{T(k-1)/K}+1 \leq t \leq \floor{Tk/K}\right\}$$ 
        \State For each partition $k$ use a first stage estimator to estimate $\hat{d}_k$ and $\hat{l}_k$ using data of all folds except $k$ (cross-fitting). 
        \State Orthogonalize treatment and outcome of observation $(i, t)$ using the predictions of the corresponding fold to get the residuals. 
        \State Use all residuals to estimate the coefficient $\theta$ using a suitable estimator.  
    \end{algorithmic}
\end{algorithm}
